# Zoom RTMS Configuration
zoom:
  client_id: "your_zoom_client_id"
  client_secret: "your_zoom_client_secret"

# Webhook Configuration (for automatic meeting join)
webhook:
  port: 8080
  path: "/webhook"

# VAD Configuration (local inference)
vad:
  packet_duration_ms: 100       # 0.1 seconds per VAD packet
  threshold: 0.5                # Speech detection threshold
  model_path: ""                # Path to VAD model (placeholder)

# ASR Configuration (KServe HTTP)
asr:
  url: "http://localhost:8080/v2/models/whisper/infer"  # KServe endpoint
  timeout_seconds: 30           # HTTP request timeout

# Speech Processor Configuration
speech_processor:
  stride_seconds: 5.0           # ASR inference interval
  silence_timeout_seconds: 1.0  # Silence to trigger speech end
  max_audio_seconds: 30.0       # Whisper max input (30s)
  pre_speech_buffer_seconds: 1.0  # Left-margin context
  history_size: 30              # Recognized sentences to keep for context

# Audio Configuration
audio:
  sample_rate: 16000  # Hz
  channels: 1  # Mono
  bit_depth: 16
  encoding: "pcm"
  # Audio stream mode:
  # - "mixed": All speakers mixed into one stream - single SpeechProcessor
  # - "individual": Separate stream per speaker - one SpeechProcessor per speaker
  stream_mode: "mixed"  # Options: "mixed", "individual"

# Recording Configuration
recording:
  enabled: true
  output_dir: "./recordings"
  save_audio: true
  save_transcripts: true
  audio_format: "wav"

# Transcription Configuration
transcription:
  output_format: "json"  # json, text, srt
  enable_timestamps: true
  enable_speaker_labels: true
  real_time_output: true

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "structured"  # structured, simple
  output: "console"  # console, file, both
  log_file: "./logs/zoom_rtms.log"

# Performance Configuration
performance:
  max_concurrent_speakers: 10
  audio_chunk_queue_size: 1000
  transcription_queue_size: 100
